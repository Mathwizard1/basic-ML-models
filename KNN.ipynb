{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN \n",
    "A supervised learning technique that considers the k(number) nearest neighbour.\n",
    "Consider the following training and validation set for a movie dataset. Your objective is to identify\n",
    "the movie class/category given in the test data set based on the number of comedy and action\n",
    "scenes. You are advised to use the concept of array to accomplish this task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNN:\n",
    "    class ScatterPoints:\n",
    "        def __init__(self, label, data):\n",
    "            self.label = label\n",
    "            self.data = data\n",
    "\n",
    "        def sld(self, other_data):\n",
    "            val = 0\n",
    "            \n",
    "            for i in range(len(self.data)):\n",
    "                val += (self.data[i] - other_data[i]) ** 2\n",
    "            return val ** (1/2)\n",
    "\n",
    "    def __init__(self, monoclass = False):\n",
    "        self.monoclass = monoclass\n",
    "        self.distance_val = []\n",
    "\n",
    "    def data_set(self, train_d, val_d, k = -1, k_limit = 20):\n",
    "        self.num = len(train_d)\n",
    "        self.k = k\n",
    "\n",
    "        self.train_data = []\n",
    "        self.val_data = []\n",
    "\n",
    "        # make the data\n",
    "        for sp in val_d:\n",
    "            self.val_data.append(self.ScatterPoints(sp[0], sp[1]))\n",
    "        for sp in train_d:\n",
    "            self.train_data.append(self.ScatterPoints(sp[0], sp[1]))\n",
    "\n",
    "        if(self.k == -1):\n",
    "            if(k_limit > self.num):\n",
    "                k_limit = int(self.num / 2)\n",
    "            self.find_best_k(k_limit)\n",
    "        \n",
    "        self.validate_model(self.k)\n",
    "        print(\"accuracy =\", self.accuracy)\n",
    "        print(\"k =\", self.k)\n",
    "\n",
    "    def validate_model(self, k, print_all: bool = False):\n",
    "        correct = 0\n",
    "        \n",
    "        num = len(self.val_data)\n",
    "        for i in range(num):\n",
    "            if(print_all):\n",
    "                print(\"data for:\", self.val_data[i].label,self.val_data[i].data)\n",
    "\n",
    "            self.calculate(self.val_data[i].data, print_all)\n",
    "                    \n",
    "            k_nearest = {}\n",
    "            for val in (self.distance_val[:k]):\n",
    "                if(val[1] in k_nearest):\n",
    "                    k_nearest[val[1]] += 1\n",
    "                else:\n",
    "                    k_nearest[val[1]] = 1               \n",
    "\n",
    "            k_nearest = dict(sorted(k_nearest.items(), key=lambda item: item[1], reverse= True))\n",
    "            pred_val = list(k_nearest.keys())[0]\n",
    "\n",
    "            if(pred_val == self.val_data[i].label):\n",
    "                correct += 1\n",
    "\n",
    "        accuracy = correct / num\n",
    "        self.accuracy = accuracy\n",
    "\n",
    "    def find_best_k(self, max_k):\n",
    "        if(max_k > self.num):\n",
    "            max_k = self.num\n",
    "\n",
    "        best_k = 1\n",
    "        best_accuracy = -1\n",
    "\n",
    "        for k in range(1, max_k + 1, 1 + self.monoclass):\n",
    "            self.validate_model(k)\n",
    "            if(self.accuracy >= best_accuracy):\n",
    "                best_accuracy = self.accuracy\n",
    "                best_k = k\n",
    "\n",
    "        self.accuracy = best_accuracy\n",
    "        self.k = best_k\n",
    "\n",
    "    def calculate(self, input_data, print_all: bool = False):\n",
    "        num = len(self.train_data)\n",
    "        distances = []\n",
    "        self.distance_val.clear()\n",
    "\n",
    "        for i in range(num):\n",
    "            distance = self.train_data[i].sld(input_data)\n",
    "            distances.append((distance, self.train_data[i].label, self.train_data[i].data))\n",
    "            self.distance_val.append((distance, self.train_data[i].label))\n",
    "        \n",
    "        # Sort by distance and make it internal\n",
    "        distances.sort(key=lambda d: d[0])\n",
    "        self.distance_val.sort(key = lambda d: d[0])\n",
    "\n",
    "        if(print_all):\n",
    "            for d in distances:\n",
    "                print(d[1],d[2],\"->\",d[0])\n",
    "\n",
    "    def run_knn(self, input_point, print_all: bool = False):\n",
    "        if(print_all):\n",
    "            print(\"input data =\", input_point)\n",
    "            print(\"k used =\", self.k)\n",
    "\n",
    "        self.calculate(input_point, print_all)\n",
    "\n",
    "        k_nearest = {}\n",
    "        for point_tuple in (self.distance_val[:self.k]):\n",
    "            if(point_tuple[1] not in k_nearest):\n",
    "                k_nearest[point_tuple[1]] = 1 / self.k\n",
    "            else:\n",
    "                k_nearest[point_tuple[1]] += 1 / self.k\n",
    "\n",
    "        k_nearest = dict(sorted(k_nearest.items(), key=lambda item: item[1], reverse= True))\n",
    "\n",
    "        # Return the most common label\n",
    "        if(self.monoclass):\n",
    "            return list(k_nearest.keys())[0]\n",
    "        return k_nearest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [(label, [comedy, action])]\n",
    "train_data = [(\"C\", (100,0)), (\"A\", (0,100)), (\"A\", (15,90)), (\"C\", (85,20))]\n",
    "validation_data = [(\"A\", (10,95)), (\"C\", (85,15))]\n",
    "\n",
    "# test data\n",
    "test_data = [(6,70), (93,23), (50,50)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 1.0\n",
      "k = 3\n",
      "data for: A (10, 95)\n",
      "A (15, 90) -> 7.0710678118654755\n",
      "A (0, 100) -> 11.180339887498949\n",
      "C (85, 20) -> 106.06601717798213\n",
      "C (100, 0) -> 130.86252328302402\n",
      "data for: C (85, 15)\n",
      "C (85, 20) -> 5.0\n",
      "C (100, 0) -> 21.213203435596427\n",
      "A (15, 90) -> 102.59142264341595\n",
      "A (0, 100) -> 120.20815280171308\n"
     ]
    }
   ],
   "source": [
    "knn = KNN(True)\n",
    "\n",
    "knn.data_set(train_data, validation_data, 3)\n",
    "knn.validate_model(1, True)\n",
    "\n",
    "#for t in test_data:\n",
    "#    print(t,\"->\", knn.run_knn(t,True))\n",
    "#    print(\"answer:\", knn.run_knn(t, True),\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parsing the Iris dataset into chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sepal_length 7.9', 'sepal_width 4.4', 'petal_length 6.9', 'petal_width 2.5', 'species']\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "all_data = {}\n",
    "with open(\"iris.csv\", \"r\") as fp:\n",
    "    csv_r = csv.reader(fp)\n",
    "    header = True\n",
    "\n",
    "    norm_val = [ 7.9, 4.4, 6.9, 2.5]\n",
    "    n = 5\n",
    "\n",
    "    for row in csv_r:\n",
    "        if(header):\n",
    "            header = False\n",
    "            print(row)\n",
    "            continue\n",
    "\n",
    "        data = []\n",
    "        for i in range(n - 1):\n",
    "            data.append(float(row[i])/norm_val[i])\n",
    "        label = row[n - 1]\n",
    "\n",
    "        if(label not in all_data):\n",
    "            all_data[label] = [(label, data)]\n",
    "        else:\n",
    "            all_data[label].append((label, data))\n",
    "    fp.close()\n",
    "\n",
    "num = 50\n",
    "\n",
    "valid_data = []\n",
    "train_data = []\n",
    "test_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation: 30\n",
      "train: 75\n",
      "test: 45\n"
     ]
    }
   ],
   "source": [
    "# parameter to divide test_train_validation\n",
    "# test(0) -> train(1)\n",
    "t_div = 0.7\n",
    "\n",
    "# train(0) -> validate(1)\n",
    "t1_div = 0.3\n",
    "\n",
    "valid_data.clear()\n",
    "train_data.clear()\n",
    "test_data.clear()\n",
    "\n",
    "for label in all_data:\n",
    "    valid_data.extend(all_data[label][:int(t1_div  * t_div * num)])\n",
    "    train_data.extend(all_data[label][int(t1_div  * t_div * num):int(t_div * num)])\n",
    "    test_data.extend(all_data[label][int(t_div * num):])\n",
    "\n",
    "print(\"validation:\",len(valid_data))\n",
    "print(\"train:\",len(train_data))\n",
    "print(\"test:\",len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 0.9666666666666667\n",
      "k = 25\n",
      "setosa prediction: {'setosa': 1.0000000000000002}\n",
      "setosa prediction: {'setosa': 1.0000000000000002}\n",
      "setosa prediction: {'setosa': 1.0000000000000002}\n",
      "setosa prediction: {'setosa': 1.0000000000000002}\n",
      "setosa prediction: {'setosa': 1.0000000000000002}\n",
      "setosa prediction: {'setosa': 1.0000000000000002}\n",
      "setosa prediction: {'setosa': 0.9600000000000003, 'versicolor': 0.04}\n",
      "setosa prediction: {'setosa': 1.0000000000000002}\n",
      "setosa prediction: {'setosa': 1.0000000000000002}\n",
      "setosa prediction: {'setosa': 1.0000000000000002}\n",
      "setosa prediction: {'setosa': 1.0000000000000002}\n",
      "setosa prediction: {'setosa': 1.0000000000000002}\n",
      "setosa prediction: {'setosa': 1.0000000000000002}\n",
      "setosa prediction: {'setosa': 1.0000000000000002}\n",
      "setosa prediction: {'setosa': 1.0000000000000002}\n",
      "versicolor prediction: {'versicolor': 0.68, 'virginica': 0.32}\n",
      "versicolor prediction: {'versicolor': 0.64, 'virginica': 0.36}\n",
      "versicolor prediction: {'versicolor': 0.8800000000000002, 'virginica': 0.12}\n",
      "versicolor prediction: {'versicolor': 0.9200000000000003, 'virginica': 0.08}\n",
      "versicolor prediction: {'versicolor': 0.9200000000000003, 'virginica': 0.08}\n",
      "versicolor prediction: {'versicolor': 0.8800000000000002, 'virginica': 0.12}\n",
      "versicolor prediction: {'versicolor': 0.7600000000000001, 'virginica': 0.24000000000000002}\n",
      "versicolor prediction: {'versicolor': 0.9200000000000003, 'virginica': 0.08}\n",
      "versicolor prediction: {'versicolor': 0.8800000000000002, 'virginica': 0.08, 'setosa': 0.04}\n",
      "versicolor prediction: {'versicolor': 0.8800000000000002, 'virginica': 0.12}\n",
      "versicolor prediction: {'versicolor': 0.8800000000000002, 'virginica': 0.12}\n",
      "versicolor prediction: {'versicolor': 0.8800000000000002, 'virginica': 0.12}\n",
      "versicolor prediction: {'versicolor': 0.8800000000000002, 'virginica': 0.12}\n",
      "versicolor prediction: {'versicolor': 0.8800000000000002, 'virginica': 0.08, 'setosa': 0.04}\n",
      "versicolor prediction: {'versicolor': 0.8800000000000002, 'virginica': 0.12}\n",
      "virginica prediction: {'virginica': 0.8800000000000002, 'versicolor': 0.12}\n",
      "virginica prediction: {'virginica': 0.8800000000000002, 'versicolor': 0.12}\n",
      "virginica prediction: {'virginica': 0.7200000000000001, 'versicolor': 0.28}\n",
      "virginica prediction: {'virginica': 0.5199999999999999, 'versicolor': 0.4799999999999999}\n",
      "virginica prediction: {'virginica': 0.8800000000000002, 'versicolor': 0.12}\n",
      "virginica prediction: {'virginica': 0.8800000000000002, 'versicolor': 0.12}\n",
      "virginica prediction: {'virginica': 0.8800000000000002, 'versicolor': 0.12}\n",
      "virginica prediction: {'virginica': 0.68, 'versicolor': 0.32}\n",
      "virginica prediction: {'virginica': 0.8800000000000002, 'versicolor': 0.12}\n",
      "virginica prediction: {'virginica': 0.8800000000000002, 'versicolor': 0.12}\n",
      "virginica prediction: {'virginica': 0.8800000000000002, 'versicolor': 0.12}\n",
      "virginica prediction: {'virginica': 0.64, 'versicolor': 0.36}\n",
      "virginica prediction: {'virginica': 0.7600000000000001, 'versicolor': 0.24000000000000002}\n",
      "virginica prediction: {'virginica': 0.8800000000000002, 'versicolor': 0.12}\n",
      "virginica prediction: {'virginica': 0.5599999999999999, 'versicolor': 0.43999999999999995}\n"
     ]
    }
   ],
   "source": [
    "Iris_Knn = KNN()\n",
    "Iris_Knn.data_set(train_data, valid_data, 25)\n",
    "\n",
    "for d in test_data:\n",
    "    pred_val = Iris_Knn.run_knn(d[1])\n",
    "    print(d[0], \"prediction:\", pred_val)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
