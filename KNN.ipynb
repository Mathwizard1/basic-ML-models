{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN \n",
    "A supervised learning technique that considers the k(number) nearest neighbour.\n",
    "Consider the following training and validation set for a movie dataset. Your objective is to identify\n",
    "the movie class/category given in the test data set based on the number of comedy and action\n",
    "scenes. You are advised to use the concept of array to accomplish this task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNN:\n",
    "    class ScatterPoints:\n",
    "        def __init__(self, label, data):\n",
    "            self.label = label\n",
    "            self.data = data\n",
    "\n",
    "        def sld(self, other_data):\n",
    "            val = 0\n",
    "            \n",
    "            for i in range(len(self.data)):\n",
    "                val += (self.data[i] - other_data[i]) ** 2\n",
    "            return val ** (1/2)\n",
    "\n",
    "    def __init__(self, monoclass = False):\n",
    "        self.monoclass = monoclass\n",
    "\n",
    "    def data_set(self, train_d, val_d, k = -1):\n",
    "        self.num = len(train_d)\n",
    "        self.k = k\n",
    "\n",
    "        self.train_data = []\n",
    "        self.val_data = []\n",
    "\n",
    "        # make the data\n",
    "        for sp in val_d:\n",
    "            self.val_data.append(self.ScatterPoints(sp[0], sp[1]))\n",
    "        for sp in train_d:\n",
    "            self.train_data.append(self.ScatterPoints(sp[0], sp[1]))\n",
    "\n",
    "        if(self.k == -1):\n",
    "            self.find_best_k(20)\n",
    "        \n",
    "        self.validate_model(self.k)\n",
    "        print(\"accuracy =\", self.accuracy)\n",
    "        print(\"k =\", self.k)\n",
    "\n",
    "    def validate_model(self, k):\n",
    "        correct = 0\n",
    "        \n",
    "        num = len(self.val_data)\n",
    "        for i in range(num):\n",
    "            self.calculate(self.val_data[i].data)\n",
    "\n",
    "            k_nearest = {}\n",
    "            for val in (self.distance_val[:k]):\n",
    "                if(val[1] in k_nearest):\n",
    "                    k_nearest[val[1]] += 1\n",
    "                else:\n",
    "                    k_nearest[val[1]] = 1               \n",
    "\n",
    "            k_nearest = dict(sorted(k_nearest.items(), key=lambda item: item[1], reverse= True))\n",
    "            pred_val = list(k_nearest.keys())[0]\n",
    "\n",
    "            if(pred_val == self.val_data[i].label):\n",
    "                correct += 1\n",
    "\n",
    "        accuracy = correct / num\n",
    "        self.accuracy = accuracy\n",
    "\n",
    "    def find_best_k(self, max_k):\n",
    "        if(max_k > self.num):\n",
    "            max_k = self.num\n",
    "\n",
    "        best_k = 1\n",
    "        best_accuracy = -1\n",
    "\n",
    "        for k in range(1, max_k + 1, 1 + self.monoclass):\n",
    "            self.validate_model(k)\n",
    "            if(self.accuracy >= best_accuracy):\n",
    "                best_accuracy = self.accuracy\n",
    "                best_k = k\n",
    "\n",
    "        self.accuracy = best_accuracy\n",
    "        self.k = best_k\n",
    "\n",
    "    def calculate(self, input_data):\n",
    "        num = len(self.train_data)\n",
    "\n",
    "        distances = []\n",
    "        for i in range(num):\n",
    "            distance = self.train_data[i].sld(input_data)\n",
    "            distances.append((distance, self.train_data[i].label))\n",
    "        \n",
    "        # Sort by distance and make it internal\n",
    "        distances.sort(key=lambda d: d[0])\n",
    "        self.distance_val = distances\n",
    "\n",
    "    def run_knn(self, input_point, print_all: bool = False):\n",
    "        self.calculate(input_point)\n",
    "\n",
    "        k_nearest = {}\n",
    "        for point_tuple in (self.distance_val[:self.k]):\n",
    "            if(point_tuple[1] not in k_nearest):\n",
    "                k_nearest[point_tuple[1]] = 1 / self.k\n",
    "            else:\n",
    "                k_nearest[point_tuple[1]] += 1 / self.k\n",
    "\n",
    "        k_nearest = dict(sorted(k_nearest.items(), key=lambda item: item[1], reverse= True))\n",
    "\n",
    "        if(print_all):\n",
    "            print(\"input data =\", input_point)\n",
    "            print(\"k used =\", self.k)\n",
    "\n",
    "            for d in self.distance_val:\n",
    "                print(\"label:\",d[1], \" sld =\", d[0])\n",
    "\n",
    "        # Return the most common label\n",
    "        if(self.monoclass):\n",
    "            return list(k_nearest.keys())[0]\n",
    "        return k_nearest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [(label, [comedy, action])]\n",
    "train_data = [(\"C\", (100,0)), (\"A\", (0,100)), (\"A\", (15,90)), (\"C\", (85,20))]\n",
    "validation_data = [(\"A\", (10,95)), (\"C\", (85,15))]\n",
    "\n",
    "# test data\n",
    "test_data = [(6,70), (93,23), (50,50)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 1.0\n",
      "k = 3\n",
      "input data = (6, 70)\n",
      "k used = 3\n",
      "label: A  sld = 21.93171219946131\n",
      "label: A  sld = 30.59411708155671\n",
      "label: C  sld = 93.49331526906082\n",
      "label: C  sld = 117.2006825918689\n",
      "answer: A \n",
      "\n",
      "input data = (93, 23)\n",
      "k used = 3\n",
      "label: C  sld = 8.54400374531753\n",
      "label: C  sld = 24.041630560342615\n",
      "label: A  sld = 102.82509421342633\n",
      "label: A  sld = 120.7393887677091\n",
      "answer: C \n",
      "\n",
      "input data = (50, 50)\n",
      "k used = 3\n",
      "label: C  sld = 46.09772228646444\n",
      "label: A  sld = 53.150729063673246\n",
      "label: C  sld = 70.71067811865476\n",
      "label: A  sld = 70.71067811865476\n",
      "answer: C \n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn = KNN(True)\n",
    "\n",
    "knn.data_set(train_data, validation_data, 3)\n",
    "\n",
    "for t in test_data:\n",
    "    print(\"answer:\", knn.run_knn(t, True),\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parsing the Iris dataset into chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sepal_length 7.9', 'sepal_width 4.4', 'petal_length 6.9', 'petal_width 2.5', 'species']\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "all_data = {}\n",
    "with open(\"iris.csv\", \"r\") as fp:\n",
    "    csv_r = csv.reader(fp)\n",
    "    header = True\n",
    "\n",
    "    norm_val = [ 7.9, 4.4, 6.9, 2.5]\n",
    "    n = 5\n",
    "\n",
    "    for row in csv_r:\n",
    "        if(header):\n",
    "            header = False\n",
    "            print(row)\n",
    "            continue\n",
    "\n",
    "        data = []\n",
    "        for i in range(n - 1):\n",
    "            data.append(float(row[i])/norm_val[i])\n",
    "        label = row[n - 1]\n",
    "\n",
    "        if(label not in all_data):\n",
    "            all_data[label] = [(label, data)]\n",
    "        else:\n",
    "            all_data[label].append((label, data))\n",
    "    fp.close()\n",
    "\n",
    "num = 50\n",
    "\n",
    "valid_data = []\n",
    "train_data = []\n",
    "test_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation: 30\n",
      "train: 75\n",
      "test: 45\n"
     ]
    }
   ],
   "source": [
    "# parameter to divide test_train_validation\n",
    "# test(0) -> train(1)\n",
    "t_div = 0.7\n",
    "\n",
    "# train(0) -> validate(1)\n",
    "t1_div = 0.3\n",
    "\n",
    "valid_data.clear()\n",
    "train_data.clear()\n",
    "test_data.clear()\n",
    "\n",
    "for label in all_data:\n",
    "    valid_data.extend(all_data[label][:int(t1_div  * t_div * num)])\n",
    "    train_data.extend(all_data[label][int(t1_div  * t_div * num):int(t_div * num)])\n",
    "    test_data.extend(all_data[label][int(t_div * num):])\n",
    "\n",
    "print(\"validation:\",len(valid_data))\n",
    "print(\"train:\",len(train_data))\n",
    "print(\"test:\",len(test_data))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 0.9666666666666667\n",
      "k = 20\n",
      "setosa prediction: {'setosa': 1.0000000000000002}\n"
     ]
    }
   ],
   "source": [
    "Iris_Knn = KNN()\n",
    "Iris_Knn.data_set(train_data, valid_data)\n",
    "\n",
    "count = 0\n",
    "\n",
    "for d in test_data:\n",
    "    pred_val = Iris_Knn.run_knn(d[1])\n",
    "    print(d[0], \"prediction:\", pred_val)\n",
    "    break\n",
    "    if(d[0] == pred_val):\n",
    "        count += 1\n",
    "\n",
    "#print(\"Answer accuracy:\", count / len(test_data))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
