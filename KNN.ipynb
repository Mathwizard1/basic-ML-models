{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN \n",
    "A supervised learning technique that considers the k(number) nearest neighbour.\n",
    "Consider the following training and validation set for a movie dataset. Your objective is to identify\n",
    "the movie class/category given in the test data set based on the number of comedy and action\n",
    "scenes. You are advised to use the concept of array to accomplish this task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import random as rd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main KNN class\n",
    "class Ag_KNN:\n",
    "    # sub class for holding the label and data\n",
    "    class Ag_Scatterpoint:\n",
    "        def __init__(self, label, data):\n",
    "            self.label = label\n",
    "            self.data = data\n",
    "\n",
    "        # sld -> Euclidean distance\n",
    "        def sld(self, other_data):\n",
    "            val = 0\n",
    "            \n",
    "            for i in range(len(self.data)):\n",
    "                val += (self.data[i] - other_data[i]) ** 2\n",
    "            return val ** (1/2)\n",
    "\n",
    "    # monoclass for single answers, monoclass = False gives the list of possible labels\n",
    "    def __init__(self, monoclass = False):\n",
    "        self.monoclass = monoclass\n",
    "        self.distance_val = []\n",
    "\n",
    "    # This is for pushing the train and validation data, and other parameters\n",
    "    def data_set(self, train_d, val_d, k = -1, k_limit = 10, print_all: bool = False):\n",
    "        self.train_Ag_num = len(train_d)\n",
    "        self.k = k\n",
    "\n",
    "        # data holding varaibles\n",
    "        self.train_data = []\n",
    "        self.val_data = []\n",
    "\n",
    "        # make the data in Scatterpoints\n",
    "        for sp in val_d:\n",
    "            self.val_data.append(self.Ag_Scatterpoint(sp[0], sp[1]))\n",
    "        for sp in train_d:\n",
    "            self.train_data.append(self.Ag_Scatterpoint(sp[0], sp[1]))\n",
    "\n",
    "        # if k not initialised find k\n",
    "        if(self.k == -1):\n",
    "            if(k_limit > self.train_Ag_num):\n",
    "                k_limit = int(self.train_Ag_num / 2)\n",
    "            self.find_best_k(k_limit)\n",
    "        \n",
    "        # display current parameters\n",
    "        self.Ag_validation(self.k, print_all)\n",
    "        print(\"accuracy =\", self.accuracy)\n",
    "        print(\"k =\", self.k)\n",
    "        print()\n",
    "\n",
    "    # this is the validation function to check for current k\n",
    "    def Ag_validation(self, k, print_all: bool):\n",
    "        correct = 0\n",
    "        \n",
    "        num = len(self.val_data)\n",
    "        for i in range(num):\n",
    "            if(print_all):\n",
    "                print(\"data for:\", self.val_data[i].label,self.val_data[i].data)\n",
    "\n",
    "            self.calculate(self.val_data[i].data, print_all)\n",
    "                    \n",
    "            # count frequency\n",
    "            Ag_k_nearest = {}\n",
    "            for val in (self.distance_val[:k]):\n",
    "                if(val[1] in Ag_k_nearest):\n",
    "                    Ag_k_nearest[val[1]] += 1\n",
    "                else:\n",
    "                    Ag_k_nearest[val[1]] = 1               \n",
    "\n",
    "            # Recreate the dictionary to make it sorted\n",
    "            Ag_k_nearest = dict(sorted(Ag_k_nearest.items(), key=lambda item: item[1], reverse= True))\n",
    "            Ag_pred_val = list(Ag_k_nearest.keys())[0]\n",
    "\n",
    "            if(Ag_pred_val == self.val_data[i].label):\n",
    "                correct += 1\n",
    "\n",
    "        accuracy = correct / num\n",
    "        self.accuracy = accuracy\n",
    "\n",
    "    # to find the best k\n",
    "    def find_best_k(self, max_k):\n",
    "        if(max_k > self.train_Ag_num):\n",
    "            max_k = self.train_Ag_num\n",
    "\n",
    "        best_k = 1\n",
    "        Ag_accuracy = -1\n",
    "\n",
    "        # try validation for each k and then update\n",
    "        for k in range(1, max_k + 1, 1 + self.monoclass):\n",
    "            self.Ag_validation(k, False)\n",
    "            if(self.accuracy > Ag_accuracy):\n",
    "                Ag_accuracy = self.accuracy\n",
    "                best_k = k\n",
    "\n",
    "        # final updates\n",
    "        self.accuracy = Ag_accuracy\n",
    "        self.k = best_k\n",
    "\n",
    "    # calculates all distances and sorts them\n",
    "    def calculate(self, input_data, print_all: bool = False):\n",
    "        num = len(self.train_data)\n",
    "        distances = []\n",
    "\n",
    "        # clear it for next data point values\n",
    "        self.distance_val.clear()\n",
    "\n",
    "        # distances\n",
    "        for i in range(num):\n",
    "            distance = self.train_data[i].sld(input_data)\n",
    "            distances.append((distance, self.train_data[i].label, self.train_data[i].data))\n",
    "            self.distance_val.append((distance, self.train_data[i].label))\n",
    "        \n",
    "        # Sort by distance and make it internal\n",
    "        distances.sort(key=lambda d: d[0])\n",
    "        self.distance_val.sort(key = lambda d: d[0])\n",
    "\n",
    "        if(print_all):\n",
    "            for d in distances:\n",
    "                print(d[1],d[2],\"->\",d[0])\n",
    "\n",
    "    # used for testing and prediction\n",
    "    def Ag_knn_run(self, input_point, print_all: bool = False):\n",
    "        if(print_all):\n",
    "            print(\"input data =\", input_point)\n",
    "            print(\"k used =\", self.k)\n",
    "\n",
    "        self.calculate(input_point, print_all)\n",
    "\n",
    "        # count frequency\n",
    "        Ag_k_nearest = {}\n",
    "        for point_tuple in (self.distance_val[:self.k]):\n",
    "            if(point_tuple[1] not in Ag_k_nearest):\n",
    "                Ag_k_nearest[point_tuple[1]] = 1 / self.k\n",
    "            else:\n",
    "                Ag_k_nearest[point_tuple[1]] += 1 / self.k\n",
    "\n",
    "        # Recreate the dictionary to make it sorted\n",
    "        Ag_k_nearest = dict(sorted(Ag_k_nearest.items(), key=lambda item: item[1], reverse= True))\n",
    "\n",
    "        # Return the most common label\n",
    "        if(self.monoclass):\n",
    "            return list(Ag_k_nearest.keys())[0]\n",
    "        return Ag_k_nearest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [(label, [comedy, action])]\n",
    "train_data = [(\"C\", (100,0)), (\"A\", (0,100)), (\"A\", (15,90)), (\"C\", (85,20))]\n",
    "validation_data = [(\"A\", (10,95)), (\"C\", (85,15))]\n",
    "\n",
    "# test data\n",
    "test_data = [(6,70), (93,23), (50,50)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data for: A (10, 95)\n",
      "A (15, 90) -> 7.0710678118654755\n",
      "A (0, 100) -> 11.180339887498949\n",
      "C (85, 20) -> 106.06601717798213\n",
      "C (100, 0) -> 130.86252328302402\n",
      "data for: C (85, 15)\n",
      "C (85, 20) -> 5.0\n",
      "C (100, 0) -> 21.213203435596427\n",
      "A (15, 90) -> 102.59142264341595\n",
      "A (0, 100) -> 120.20815280171308\n",
      "accuracy = 1.0\n",
      "k = 1\n",
      "\n",
      "data for: A (10, 95)\n",
      "A (15, 90) -> 7.0710678118654755\n",
      "A (0, 100) -> 11.180339887498949\n",
      "C (85, 20) -> 106.06601717798213\n",
      "C (100, 0) -> 130.86252328302402\n",
      "data for: C (85, 15)\n",
      "C (85, 20) -> 5.0\n",
      "C (100, 0) -> 21.213203435596427\n",
      "A (15, 90) -> 102.59142264341595\n",
      "A (0, 100) -> 120.20815280171308\n",
      "accuracy = 1.0\n",
      "k = 3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test knn\n",
    "smal_Ag_knn = Ag_KNN(True)\n",
    "\n",
    "# print validation for k = 1\n",
    "smal_Ag_knn.data_set(train_data, validation_data, 1, print_all= True)\n",
    "\n",
    "# print validation for k = 3\n",
    "smal_Ag_knn.data_set(train_data, validation_data, 3, print_all= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data: \n",
      "(6, 70) -> A\n",
      "(93, 23) -> C\n",
      "input data = (50, 50)\n",
      "k used = 3\n",
      "C (85, 20) -> 46.09772228646444\n",
      "A (15, 90) -> 53.150729063673246\n",
      "C (100, 0) -> 70.71067811865476\n",
      "A (0, 100) -> 70.71067811865476\n",
      "(50, 50) -> C\n"
     ]
    }
   ],
   "source": [
    "print(\"Test data: \")\n",
    "\n",
    "# Test Data values\n",
    "print(test_data[0] ,\"->\", smal_Ag_knn.Ag_knn_run(test_data[0]))\n",
    "print(test_data[1] ,\"->\", smal_Ag_knn.Ag_knn_run(test_data[1]))\n",
    "print(test_data[2] ,\"->\", smal_Ag_knn.Ag_knn_run(test_data[2], True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parsing the Iris dataset into chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sepal_length 7.9', 'sepal_width 4.4', 'petal_length 6.9', 'petal_width 2.5', 'species']\n"
     ]
    }
   ],
   "source": [
    "# Dictionary to hold all data\n",
    "all_data = {}\n",
    "\n",
    "# file parsing .csv\n",
    "with open(\"iris.csv\", \"r\") as fp:\n",
    "    csv_r = csv.reader(fp)\n",
    "    header = True\n",
    "\n",
    "    # hard coded normalisation values\n",
    "    norm_val = [7.9, 4.4, 6.9, 2.5]\n",
    "    n = 5\n",
    "\n",
    "    for row in csv_r:\n",
    "        if(header):\n",
    "            header = False\n",
    "            print(row)\n",
    "            continue\n",
    "\n",
    "        data = []\n",
    "        for i in range(n - 1):\n",
    "            data.append(float(row[i])/norm_val[i])\n",
    "        label = row[n - 1]\n",
    "\n",
    "        if(label not in all_data):\n",
    "            all_data[label] = [(label, data)]\n",
    "        else:\n",
    "            all_data[label].append((label, data))\n",
    "    fp.close()\n",
    "\n",
    "num = 50\n",
    "\n",
    "valid_data = []\n",
    "train_data = []\n",
    "test_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation: 30\n",
      "train: 75\n",
      "test: 45\n"
     ]
    }
   ],
   "source": [
    "# parameter to divide test_train_validation\n",
    "# test(0) -> train(1)\n",
    "Ag_test_train_div = 0.7\n",
    "# train(0) -> validate(1)\n",
    "Ag_valid_train_div = 0.3\n",
    "\n",
    "# no random trials\n",
    "Ag_rd_num = 0\n",
    "\n",
    "valid_data.clear()\n",
    "train_data.clear()\n",
    "test_data.clear()\n",
    "\n",
    "# Randomise\n",
    "def Ag_random(Ag_num = 0):\n",
    "    rd.seed(Ag_num)\n",
    "    if(Ag_num > 0):\n",
    "        for label in all_data:\n",
    "            print(\"1\",all_data[label][0])\n",
    "            shf_label = all_data[label]\n",
    "            rd.shuffle(shf_label)\n",
    "            all_data[label] = shf_label\n",
    "            print(\"2\",all_data[label][0],\"\\n\")\n",
    "\n",
    "Ag_random(Ag_rd_num)\n",
    "\n",
    "# push the correct lens of data in the lists\n",
    "for label in all_data:\n",
    "    valid_data.extend(all_data[label][:int(Ag_valid_train_div  * Ag_test_train_div * num)])\n",
    "    train_data.extend(all_data[label][int(Ag_valid_train_div  * Ag_test_train_div * num):int(Ag_test_train_div * num)])\n",
    "    test_data.extend(all_data[label][int(Ag_test_train_div * num):])\n",
    "\n",
    "print(\"validation:\",len(valid_data))\n",
    "print(\"train:\",len(train_data))\n",
    "print(\"test:\",len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 0.9666666666666667\n",
      "k = 1\n",
      "\n",
      "setosa prediction: setosa\n",
      "setosa prediction: setosa\n",
      "setosa prediction: setosa\n",
      "setosa prediction: setosa\n",
      "setosa prediction: setosa\n",
      "setosa prediction: setosa\n",
      "setosa prediction: setosa\n",
      "setosa prediction: setosa\n",
      "setosa prediction: setosa\n",
      "setosa prediction: setosa\n",
      "setosa prediction: setosa\n",
      "setosa prediction: setosa\n",
      "setosa prediction: setosa\n",
      "setosa prediction: setosa\n",
      "setosa prediction: setosa\n",
      "versicolor prediction: versicolor\n",
      "versicolor prediction: versicolor\n",
      "versicolor prediction: versicolor\n",
      "versicolor prediction: versicolor\n",
      "versicolor prediction: versicolor\n",
      "versicolor prediction: versicolor\n",
      "versicolor prediction: versicolor\n",
      "versicolor prediction: versicolor\n",
      "versicolor prediction: versicolor\n",
      "versicolor prediction: versicolor\n",
      "versicolor prediction: versicolor\n",
      "versicolor prediction: versicolor\n",
      "versicolor prediction: versicolor\n",
      "versicolor prediction: versicolor\n",
      "versicolor prediction: versicolor\n",
      "virginica prediction: virginica\n",
      "virginica prediction: virginica\n",
      "virginica prediction: virginica\n",
      "virginica prediction: virginica\n",
      "virginica prediction: virginica\n",
      "virginica prediction: virginica\n",
      "virginica prediction: virginica\n",
      "virginica prediction: virginica\n",
      "virginica prediction: virginica\n",
      "virginica prediction: virginica\n",
      "virginica prediction: virginica\n",
      "virginica prediction: virginica\n",
      "virginica prediction: virginica\n",
      "virginica prediction: virginica\n",
      "virginica prediction: virginica\n"
     ]
    }
   ],
   "source": [
    "Ag_Iris_Knn = Ag_KNN(True)\n",
    "Ag_Iris_Knn.data_set(train_data, valid_data)\n",
    "\n",
    "if(Ag_rd_num > 0):\n",
    "    print(\"Seeded random\", Ag_rd_num)\n",
    "\n",
    "for d in test_data:\n",
    "    Ag_pred_val = Ag_Iris_Knn.Ag_knn_run(d[1])\n",
    "    print(d[0], \"prediction:\", Ag_pred_val)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
