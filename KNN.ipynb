{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN \n",
    "A supervised learning technique that considers the k(number) nearest neighbour.\n",
    "Consider the following training and validation set for a movie dataset. Your objective is to identify\n",
    "the movie class/category given in the test data set based on the number of comedy and action\n",
    "scenes. You are advised to use the concept of array to accomplish this task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNN:\n",
    "    class ScatterPoints:\n",
    "        def __init__(self, label, data):\n",
    "            self.label = label\n",
    "            self.data = data\n",
    "\n",
    "        def sld(self, other_data):\n",
    "            val = 0\n",
    "            \n",
    "            for i in range(len(self.data)):\n",
    "                val += (self.data[i] - other_data[i]) ** 2\n",
    "            return val ** (1/2)\n",
    "\n",
    "    def __init__(self, monoclass = False):\n",
    "        self.monoclass = monoclass\n",
    "\n",
    "    def data_set(self, train_d, val_d, k = -1, k_limit = 20):\n",
    "        self.num = len(train_d)\n",
    "        self.k = k\n",
    "\n",
    "        self.train_data = []\n",
    "        self.val_data = []\n",
    "\n",
    "        # make the data\n",
    "        for sp in val_d:\n",
    "            self.val_data.append(self.ScatterPoints(sp[0], sp[1]))\n",
    "        for sp in train_d:\n",
    "            self.train_data.append(self.ScatterPoints(sp[0], sp[1]))\n",
    "\n",
    "        if(self.k == -1):\n",
    "            if(k_limit > self.num):\n",
    "                k_limit = int(self.num / 2)\n",
    "            self.find_best_k(k_limit)\n",
    "        \n",
    "        self.validate_model(self.k)\n",
    "        print(\"accuracy =\", self.accuracy)\n",
    "        print(\"k =\", self.k)\n",
    "\n",
    "    def validate_model(self, k, print_all = False):\n",
    "        correct = 0\n",
    "        \n",
    "        num = len(self.val_data)\n",
    "        for i in range(num):\n",
    "            self.calculate(self.val_data[i].data)\n",
    "\n",
    "            if(print_all):\n",
    "                print(\"data for:\", self.val_data[i].label,self.val_data[i].data)\n",
    "                for d in self.distance_val:\n",
    "                    print(\"label:\",d[1], \" sld =\", d[0])\n",
    "                    \n",
    "            k_nearest = {}\n",
    "            for val in (self.distance_val[:k]):\n",
    "                if(val[1] in k_nearest):\n",
    "                    k_nearest[val[1]] += 1\n",
    "                else:\n",
    "                    k_nearest[val[1]] = 1               \n",
    "\n",
    "            k_nearest = dict(sorted(k_nearest.items(), key=lambda item: item[1], reverse= True))\n",
    "            pred_val = list(k_nearest.keys())[0]\n",
    "\n",
    "            if(pred_val == self.val_data[i].label):\n",
    "                correct += 1\n",
    "\n",
    "        accuracy = correct / num\n",
    "        self.accuracy = accuracy\n",
    "\n",
    "    def find_best_k(self, max_k):\n",
    "        if(max_k > self.num):\n",
    "            max_k = self.num\n",
    "\n",
    "        best_k = 1\n",
    "        best_accuracy = -1\n",
    "\n",
    "        for k in range(1, max_k + 1, 1 + self.monoclass):\n",
    "            self.validate_model(k)\n",
    "            if(self.accuracy >= best_accuracy):\n",
    "                best_accuracy = self.accuracy\n",
    "                best_k = k\n",
    "\n",
    "        self.accuracy = best_accuracy\n",
    "        self.k = best_k\n",
    "\n",
    "    def calculate(self, input_data):\n",
    "        num = len(self.train_data)\n",
    "\n",
    "        distances = []\n",
    "        for i in range(num):\n",
    "            distance = self.train_data[i].sld(input_data)\n",
    "            distances.append((distance, self.train_data[i].label))\n",
    "        \n",
    "        # Sort by distance and make it internal\n",
    "        distances.sort(key=lambda d: d[0])\n",
    "        self.distance_val = distances\n",
    "\n",
    "    def run_knn(self, input_point, print_all: bool = False):\n",
    "        self.calculate(input_point)\n",
    "\n",
    "        k_nearest = {}\n",
    "        for point_tuple in (self.distance_val[:self.k]):\n",
    "            if(point_tuple[1] not in k_nearest):\n",
    "                k_nearest[point_tuple[1]] = 1 / self.k\n",
    "            else:\n",
    "                k_nearest[point_tuple[1]] += 1 / self.k\n",
    "\n",
    "        k_nearest = dict(sorted(k_nearest.items(), key=lambda item: item[1], reverse= True))\n",
    "\n",
    "        if(print_all):\n",
    "            print(\"input data =\", input_point)\n",
    "            print(\"k used =\", self.k)\n",
    "\n",
    "            for d in self.distance_val:\n",
    "                print(\"label:\",d[1], \" sld =\", d[0])\n",
    "\n",
    "        # Return the most common label\n",
    "        if(self.monoclass):\n",
    "            return list(k_nearest.keys())[0]\n",
    "        return k_nearest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [(label, [comedy, action])]\n",
    "train_data = [(\"C\", (100,0)), (\"A\", (0,100)), (\"A\", (15,90)), (\"C\", (85,20))]\n",
    "validation_data = [(\"A\", (10,95)), (\"C\", (85,15))]\n",
    "\n",
    "# test data\n",
    "test_data = [(6,70), (93,23), (50,50)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 1.0\n",
      "k = 3\n",
      "data for: A (10, 95)\n",
      "label: A  sld = 7.0710678118654755\n",
      "label: A  sld = 11.180339887498949\n",
      "label: C  sld = 106.06601717798213\n",
      "label: C  sld = 130.86252328302402\n",
      "data for: C (85, 15)\n",
      "label: C  sld = 5.0\n",
      "label: C  sld = 21.213203435596427\n",
      "label: A  sld = 102.59142264341595\n",
      "label: A  sld = 120.20815280171308\n"
     ]
    }
   ],
   "source": [
    "knn = KNN(True)\n",
    "\n",
    "knn.data_set(train_data, validation_data, 3)\n",
    "knn.validate_model(1, True)\n",
    "\n",
    "#for t in test_data:\n",
    "#    print(t,\"->\", knn.run_knn(t,True))\n",
    "#    print(\"answer:\", knn.run_knn(t, True),\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parsing the Iris dataset into chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'iris.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[101], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcsv\u001b[39;00m\n\u001b[0;32m      3\u001b[0m all_data \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43miris.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m fp:\n\u001b[0;32m      5\u001b[0m     csv_r \u001b[38;5;241m=\u001b[39m csv\u001b[38;5;241m.\u001b[39mreader(fp)\n\u001b[0;32m      6\u001b[0m     header \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\anshu_r9i5971\\Desktop\\Python\\ML working\\basic model\\.venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    322\u001b[0m     )\n\u001b[1;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'iris.csv'"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "all_data = {}\n",
    "with open(\"iris.csv\", \"r\") as fp:\n",
    "    csv_r = csv.reader(fp)\n",
    "    header = True\n",
    "\n",
    "    norm_val = [ 7.9, 4.4, 6.9, 2.5]\n",
    "    n = 5\n",
    "\n",
    "    for row in csv_r:\n",
    "        if(header):\n",
    "            header = False\n",
    "            print(row)\n",
    "            continue\n",
    "\n",
    "        data = []\n",
    "        for i in range(n - 1):\n",
    "            data.append(float(row[i])/norm_val[i])\n",
    "        label = row[n - 1]\n",
    "\n",
    "        if(label not in all_data):\n",
    "            all_data[label] = [(label, data)]\n",
    "        else:\n",
    "            all_data[label].append((label, data))\n",
    "    fp.close()\n",
    "\n",
    "num = 50\n",
    "\n",
    "valid_data = []\n",
    "train_data = []\n",
    "test_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation: 30\n",
      "train: 75\n",
      "test: 45\n"
     ]
    }
   ],
   "source": [
    "# parameter to divide test_train_validation\n",
    "# test(0) -> train(1)\n",
    "t_div = 0.7\n",
    "\n",
    "# train(0) -> validate(1)\n",
    "t1_div = 0.3\n",
    "\n",
    "valid_data.clear()\n",
    "train_data.clear()\n",
    "test_data.clear()\n",
    "\n",
    "for label in all_data:\n",
    "    valid_data.extend(all_data[label][:int(t1_div  * t_div * num)])\n",
    "    train_data.extend(all_data[label][int(t1_div  * t_div * num):int(t_div * num)])\n",
    "    test_data.extend(all_data[label][int(t_div * num):])\n",
    "\n",
    "print(\"validation:\",len(valid_data))\n",
    "print(\"train:\",len(train_data))\n",
    "print(\"test:\",len(test_data))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 0.9666666666666667\n",
      "k = 20\n",
      "setosa prediction: {'setosa': 1.0000000000000002}\n"
     ]
    }
   ],
   "source": [
    "Iris_Knn = KNN()\n",
    "Iris_Knn.data_set(train_data, valid_data)\n",
    "\n",
    "count = 0\n",
    "\n",
    "for d in test_data:\n",
    "    pred_val = Iris_Knn.run_knn(d[1])\n",
    "    print(d[0], \"prediction:\", pred_val)\n",
    "    break\n",
    "    if(d[0] == pred_val):\n",
    "        count += 1\n",
    "\n",
    "#print(\"Answer accuracy:\", count / len(test_data))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
